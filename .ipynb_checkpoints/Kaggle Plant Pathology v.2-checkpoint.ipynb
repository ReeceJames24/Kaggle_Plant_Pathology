{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "special-evanescence",
   "metadata": {},
   "source": [
    "This notebook is running on C Desktop although the data folder is placed in D. \n",
    "\n",
    "Make use of this root path when needed:\n",
    "\n",
    "__D:\\Kaggle Plant Path__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "adjustable-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from shutil import copyfile\n",
    "from shutil import copy2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "lasting-breakfast",
   "metadata": {},
   "source": [
    "## Data Preprocessing\n",
    "\n",
    "- ImageDataGenerator requires our images to be placed in subdirectories named after their respective labels. In our case, our images currently are unlabelled and are not divided into subdirectories. We are, however, given a csv file with the labels per image file.\n",
    "- We must first create subdirectories followed by a loop that places each training image in its corrrect subdirectory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "rolled-symphony",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>800113bb65efe69e.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8002cb321f8bfcdf.jpg</td>\n",
       "      <td>scab frog_eye_leaf_spot complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>80070f7fb5e2ccaa.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>80077517781fb94f.jpg</td>\n",
       "      <td>scab</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>800cbf0ff87721f8.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image                           labels\n",
       "0  800113bb65efe69e.jpg                          healthy\n",
       "1  8002cb321f8bfcdf.jpg  scab frog_eye_leaf_spot complex\n",
       "2  80070f7fb5e2ccaa.jpg                             scab\n",
       "3  80077517781fb94f.jpg                             scab\n",
       "4  800cbf0ff87721f8.jpg                          complex"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get the labels by first importing the label csv\n",
    "root = 'D:\\Kaggle Plant Path'\n",
    "label_csv = os.path.join(root,'train.csv')\n",
    "df = pd.read_csv(label_csv)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "brazilian-tsunami",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex',\n",
       " 'frog_eye_leaf_spot',\n",
       " 'frog_eye_leaf_spot complex',\n",
       " 'healthy',\n",
       " 'powdery_mildew',\n",
       " 'powdery_mildew complex',\n",
       " 'rust',\n",
       " 'rust complex',\n",
       " 'rust frog_eye_leaf_spot',\n",
       " 'scab',\n",
       " 'scab frog_eye_leaf_spot',\n",
       " 'scab frog_eye_leaf_spot complex']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = list(df['labels'])\n",
    "labels = list(np.unique(a))\n",
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lasting-contribution",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create primary directory and necessary subdirectories\n",
    "train_dir = os.path.join(root,'plants-training')\n",
    "to_create = [train_dir]\n",
    "for label in labels: #creates list of all necessary subdirectories to make\n",
    "    to_create.append(os.path.join(train_dir,label))\n",
    "\n",
    "#loop to create directories using paths in the to_create list\n",
    "'''for directory in to_create:\n",
    "    try:\n",
    "        os.mkdir(directory)\n",
    "        print(directory, 'created')\n",
    "    except:\n",
    "        print(directory, 'creation failed')''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "enhanced-roller",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create alias variables for subdirectories for ease of reference\n",
    "'''var_list = ['complx', 'frog_eye_leaf_spot', 'frog_eye_leaf_spot_complx', 'healthy', 'powdery_mildew', 'powdery_mildew_complx','rust', 'rust_complx', 'rust_frog_eye_leaf_spot', 'scab', 'scab_frog_eye_leaf_spot', 'scab_frog_eye_leaf_spot_complx']\n",
    "class_dir = to_create[1:] #list that includes only subdirectory paths of the labels\n",
    "''';\n",
    "#this allows me to avoid the /f error when manually assigning the string of the path to variables (ex: \\\\frog_leaf would turn to \\x0rog_leaf)\n",
    "'''for (variable,subdir_path) in zip(var_list,class_dir):\n",
    "    exec(\"%s = %a\" % (variable, subdir_path))''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "alternative-jason",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loop over zip object of the file names and labels in train.csv and copy files to their respective subdirectories\n",
    "files = list(df['image'])\n",
    "y_train = list(df['labels'])\n",
    "\n",
    "images_dir = os.path.join(root,'train_images')\n",
    "\n",
    "'''\n",
    "for (file_name,label) in zip(files,y_train):\n",
    "    try:\n",
    "        if label == 'complex':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(complx,file_name))\n",
    "        elif label == 'frog_eye_leaf_spot':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(frog_eye_leaf_spot,file_name))\n",
    "        elif label == 'frog_eye_leaf_spot complex':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(frog_eye_leaf_spot_complx,file_name))\n",
    "        elif label == 'healthy':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(healthy,file_name))\n",
    "        elif label ==  'powdery_mildew':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(powdery_mildew,file_name))\n",
    "        elif label == 'powdery_mildew complex':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(powdery_mildew_complx,file_name))\n",
    "        elif label == 'rust':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path,os.path.join(rust,file_name))\n",
    "        elif label == 'rust complex':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(rust_complx,file_name))\n",
    "        elif label == 'rust frog_eye_leaf_spot':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path,os.path.join(rust_frog_eye_leaf_spot,file_name))\n",
    "        elif label == 'scab':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(scab,file_name))\n",
    "        elif label == 'scab frog_eye_leaf_spot':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(scab_frog_eye_leaf_spot,file_name))\n",
    "        elif label == 'scab frog_eye_leaf_spot complex':\n",
    "            file_path = os.path.join(images_dir,file_name)\n",
    "            copy2(file_path, os.path.join(scab_frog_eye_leaf_spot_complx,file_name))\n",
    "        else:\n",
    "            print('yo what disease is this')\n",
    "    except:\n",
    "        print('failed to copy ', file_name, ' with label ', label)''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cardiovascular-harvey",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 13977 images belonging to 12 classes.\n",
      "Found 4655 images belonging to 12 classes.\n"
     ]
    }
   ],
   "source": [
    "#Create ImageDataGenerators and apply image processing arguments (should find 12 classes)\n",
    "datagen = ImageDataGenerator(rescale = 1.0/255.,\n",
    "                                   rotation_range = 40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   fill_mode = 'nearest',\n",
    "                                   validation_split=0.25)\n",
    "                                   \n",
    "train_generator = datagen.flow_from_directory(train_dir,\n",
    "                                                    subset='training',\n",
    "                                                    target_size = (200,200),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'sparse')\n",
    "validation_generator = datagen.flow_from_directory(train_dir,\n",
    "                                                    subset='validation',\n",
    "                                                    target_size = (200,200),\n",
    "                                                    batch_size = 32,\n",
    "                                                    class_mode = 'sparse')\n",
    "                                                   \n",
    "\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=validation_generator.n//validation_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "organizational-pontiac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define callback \n",
    "\n",
    "class myCallback(keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if(logs.get('acc') is not None and logs.get('acc')>0.75):\n",
    "            print('Reached 75% training acc. Stopping Training!')\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "disabled-narrative",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define and compile Model\n",
    "callbacks = myCallback()\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, (2,2), activation='relu', input_shape=(200,200,3)),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(32, (2,2), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Conv2D(32,(2,2), activation='relu'),\n",
    "    keras.layers.MaxPooling2D(2,2),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(1024,activation='relu'),\n",
    "    keras.layers.Dropout(0.20),\n",
    "    keras.layers.Dense(12,activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer = 'adam', \n",
    "             loss = 'sparse_categorical_crossentropy',\n",
    "             metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "occupied-latin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 437 steps, validate for 146 steps\n",
      "Epoch 1/10\n",
      "437/437 [==============================] - 2791s 6s/step - loss: 1.6778 - accuracy: 0.3881 - val_loss: 1.4814 - val_accuracy: 0.4520\n",
      "Epoch 2/10\n",
      "437/437 [==============================] - 2743s 6s/step - loss: 1.4092 - accuracy: 0.4976 - val_loss: 1.2589 - val_accuracy: 0.5742\n",
      "Epoch 3/10\n",
      "437/437 [==============================] - 2740s 6s/step - loss: 1.2609 - accuracy: 0.5444 - val_loss: 1.1301 - val_accuracy: 0.6161\n",
      "Epoch 4/10\n",
      "437/437 [==============================] - 2759s 6s/step - loss: 1.1641 - accuracy: 0.5807 - val_loss: 1.1289 - val_accuracy: 0.5996\n",
      "Epoch 5/10\n",
      "437/437 [==============================] - 2737s 6s/step - loss: 1.1136 - accuracy: 0.5988 - val_loss: 1.1413 - val_accuracy: 0.6137\n",
      "Epoch 6/10\n",
      "437/437 [==============================] - 2753s 6s/step - loss: 1.0748 - accuracy: 0.6162 - val_loss: 0.9778 - val_accuracy: 0.6610\n",
      "Epoch 7/10\n",
      "437/437 [==============================] - 2796s 6s/step - loss: 1.0303 - accuracy: 0.6319 - val_loss: 0.9763 - val_accuracy: 0.6649\n",
      "Epoch 8/10\n",
      "437/437 [==============================] - 2824s 6s/step - loss: 1.0017 - accuracy: 0.6433 - val_loss: 1.0035 - val_accuracy: 0.6505\n",
      "Epoch 9/10\n",
      "437/437 [==============================] - 2886s 7s/step - loss: 0.9709 - accuracy: 0.6557 - val_loss: 0.9615 - val_accuracy: 0.6685\n",
      "Epoch 10/10\n",
      "437/437 [==============================] - 2895s 7s/step - loss: 0.9260 - accuracy: 0.6723 - val_loss: 0.9117 - val_accuracy: 0.6924\n",
      "WARNING:tensorflow:From C:\\Users\\Toffee\\anaconda3\\envs\\tensorflow_gpu\\lib\\site-packages\\tensorflow_core\\python\\ops\\resource_variable_ops.py:1786: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "INFO:tensorflow:Assets written to: D:\\Kaggle Plant Path\\model_v2\\assets\n"
     ]
    }
   ],
   "source": [
    "#Train Model\n",
    "\n",
    "history = model.fit(train_generator, \n",
    "                    epochs = 10,\n",
    "                    validation_data = validation_generator,\n",
    "                    callbacks = [callbacks])\n",
    "\n",
    "#Create folder to save model in\n",
    "model_folder = os.path.join(root,\"model_v2\")\n",
    "os.mkdir(model_folder)\n",
    "model.save(model_folder)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "unexpected-chocolate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13977"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#BONUS (for future ref): this is how you get the filenames taken by the generator\n",
    "train_files = train_generator.filenames\n",
    "len(train_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "hydraulic-serum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3 images belonging to 1 classes.\n"
     ]
    }
   ],
   "source": [
    "#Predict test data\n",
    "\n",
    "test_dir = os.path.join(root,'test_images')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255)\n",
    "\n",
    "target_prediction_steps = 1\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(test_dir,\n",
    "                                                    target_size = (200,200),\n",
    "                                                    batch_size = target_prediction_steps,\n",
    "                                                    class_mode = None)\n",
    "\n",
    "test_images = test_generator.filenames\n",
    "num_samples = len(test_images)\n",
    "\n",
    "test_dir\n",
    "predictions = model.predict(test_generator, steps = num_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "solved-garlic",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex',\n",
       " 'frog_eye_leaf_spot',\n",
       " 'frog_eye_leaf_spot complex',\n",
       " 'healthy',\n",
       " 'powdery_mildew',\n",
       " 'powdery_mildew complex',\n",
       " 'rust',\n",
       " 'rust complex',\n",
       " 'rust frog_eye_leaf_spot',\n",
       " 'scab',\n",
       " 'scab frog_eye_leaf_spot',\n",
       " 'scab frog_eye_leaf_spot complex']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = list(train_generator.class_indices.keys()) # gives us the list of classes in the correct order\n",
    "classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "objective-gateway",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[5.41043580e-01, 3.55545506e-02, 7.06244558e-02, 4.34366411e-05,\n",
       "        1.70191806e-02, 4.03938703e-02, 1.40749365e-02, 1.16720805e-02,\n",
       "        9.83693358e-03, 3.28349206e-03, 1.76599637e-01, 7.98538849e-02],\n",
       "       [5.95017113e-02, 1.53353845e-03, 2.13752079e-04, 6.01123393e-01,\n",
       "        2.30773562e-03, 8.22508373e-05, 2.16783300e-01, 1.35173905e-03,\n",
       "        2.12462177e-03, 1.06846020e-01, 8.08615610e-03, 4.57752067e-05],\n",
       "       [4.23706993e-02, 5.11347055e-01, 7.01766135e-03, 3.99480946e-03,\n",
       "        2.18866087e-04, 7.87784811e-05, 3.16694438e-01, 6.09778799e-03,\n",
       "        1.18474290e-02, 2.65770662e-03, 9.57935825e-02, 1.88118557e-03]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "broad-domain",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['complex', 'healthy', 'frog_eye_leaf_spot']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's return the respective labels instead of the probability values\n",
    "max_predictions = predictions.argmax(axis=1) #shape of (3,)\n",
    "\n",
    "label_predictions = [classes[predictions] for predictions in max_predictions]\n",
    "label_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "indirect-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['85f8cb619c66b863.jpg', 'complex'],\n",
       "       ['ad8770db05586b59.jpg', 'healthy'],\n",
       "       ['c7b03e718489f3ca.jpg', 'frog_eye_leaf_spot']], dtype='<U20')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Place image names and predicted labels in pd dataframe to convert to csv\n",
    "test_images = os.listdir(os.path.join(test_dir,'testing'))\n",
    "pred_arr = np.c_[test_images,label_predictions]\n",
    "pred_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "polyphonic-activity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>85f8cb619c66b863.jpg</td>\n",
       "      <td>complex</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ad8770db05586b59.jpg</td>\n",
       "      <td>healthy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>c7b03e718489f3ca.jpg</td>\n",
       "      <td>frog_eye_leaf_spot</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  image              labels\n",
       "0  85f8cb619c66b863.jpg             complex\n",
       "1  ad8770db05586b59.jpg             healthy\n",
       "2  c7b03e718489f3ca.jpg  frog_eye_leaf_spot"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert array to datafram \n",
    "submission_df = pd.DataFrame(data = pred_arr,\n",
    "                            index = None,\n",
    "                             columns = ['image', 'labels'])\n",
    "submission_df                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "developed-groove",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_df.to_csv('Chummi_Apple_Leaves_v2.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "strange-township",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dependent-dominant",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu",
   "language": "python",
   "name": "tensorflow_gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
